"""
Script : check_integrity.py
But : VÃ©rifier l'intÃ©gritÃ© d'un fichier de donnÃ©es avant migration vers MongoDB
Auteur : GPT-5 (Assistant Python)
"""

import pandas as pd
import numpy as np
import os
import sys

# === CONFIGURATION ===
FICHIER = "healthcare_dataset_purge.csv"  # Nom du fichier Ã  tester (CSV ou XLSX)
# csv_file_path = '../data/healthcare_dataset_purge.csv'

def charger_fichier(fichier):
    """Charge un fichier CSV ou Excel et retourne un DataFrame pandas."""
    if not os.path.exists(fichier):
        print(f"âŒ Erreur : Le fichier '{fichier}' est introuvable.")
        sys.exit(1)

    try:
        if fichier.endswith(".csv"):
            df = pd.read_csv(fichier)
        elif fichier.endswith((".xls", ".xlsx")):
            df = pd.read_excel(fichier)
        else:
            print("âŒ Format non supportÃ©. Utilise un fichier CSV ou Excel.")
            sys.exit(1)
    except Exception as e:
        print(f"âŒ Erreur lors du chargement du fichier : {e}")
        sys.exit(1)
    return df


def verifier_colonnes(df):
    """Affiche la liste des colonnes et leur type."""
    print("\nğŸ“Š Colonnes disponibles et types de donnÃ©es :")
    print(df.dtypes)
    print(f"\nNombre total de colonnes : {len(df.columns)}")


def verifier_valeurs_manquantes(df):
    """VÃ©rifie la prÃ©sence de valeurs manquantes."""
    print("\nğŸ” VÃ©rification des valeurs manquantes :")
    missing = df.isnull().sum()
    total_missing = missing.sum()

    if total_missing == 0:
        print("âœ… Aucune valeur manquante dÃ©tectÃ©e.")
    else:
        print(f"âš ï¸ Valeurs manquantes dÃ©tectÃ©es dans {sum(missing > 0)} colonnes :")
        print(missing[missing > 0])


def verifier_doublons(df):
    """VÃ©rifie les doublons dans le DataFrame."""
    print("\nğŸ§¬ VÃ©rification des doublons :")
    duplicates = df.duplicated().sum()
    if duplicates == 0:
        print("âœ… Aucun doublon dÃ©tectÃ©.")
    else:
        print(f"âš ï¸ {duplicates} doublon(s) dÃ©tectÃ©(s).")
        print("   â†’ Recommandation : supprimer via df.drop_duplicates(inplace=True)")


def verifier_types_mixtes(df):
    """DÃ©tecte les colonnes contenant des types de donnÃ©es mixtes."""
    print("\nğŸ§© VÃ©rification des colonnes Ã  types mixtes :")
    mixed_cols = []
    for col in df.columns:
        types_uniques = df[col].map(type).nunique()
        if types_uniques > 1:
            mixed_cols.append(col)

    if mixed_cols:
        print(f"âš ï¸ Colonnes avec types mixtes : {mixed_cols}")
        print("   â†’ Recommandation : uniformiser les types (ex: int â†’ str)")
    else:
        print("âœ… Aucune colonne Ã  types mixtes dÃ©tectÃ©e.")


def generer_recommandations(df):
    """Fournit des recommandations avant migration MongoDB."""
    print("\nğŸ§  Recommandations avant migration vers MongoDB :")
    print("""
âœ… 1. Nettoyer les valeurs manquantes (remplacer, supprimer ou normaliser)
âœ… 2. Supprimer les doublons
âœ… 3. S'assurer que les colonnes clÃ©s sont uniques
âœ… 4. Convertir les types incompatibles (dates, boolÃ©ens, nombres)
âœ… 5. VÃ©rifier l'encodage UTF-8 pour Ã©viter les caractÃ¨res illisibles
âœ… 6. Exporter le fichier final en JSON pour import MongoDB :
       df.to_json('data_clean.json', orient='records', lines=True)
    """)


def main():
    print("=== ğŸ§¾ Test d'intÃ©gritÃ© des donnÃ©es avant migration MongoDB ===")

    df = charger_fichier(FICHIER)
    print(f"\nâœ… Fichier chargÃ© avec succÃ¨s : {FICHIER}")
    print(f"â†’ {df.shape[0]} lignes, {df.shape[1]} colonnes")

    verifier_colonnes(df)
    verifier_valeurs_manquantes(df)
    verifier_doublons(df)
    verifier_types_mixtes(df)
    generer_recommandations(df)

    print("\nğŸ¯ VÃ©rification terminÃ©e !")


if __name__ == "__main__":
    main()
